---
생성일: "2024-08-31T16:26:00.000Z"
Last edited time: "2024-09-12T11:58:00.000Z"
태그: ["Remind"]
pid: "c37c989f-7c24-4a52-8c7b-6888b58d59fb"
title: "LG Aimers 5기 복기"
slug: "after-lg-aimer-5th"
last_edited_time: "2024-09-12T11:58:00.000Z"
---

LG Aimers는 석학들이 분야에 대해 강의하고, 참가자들이 챌린지를 통해 배운 내용을 실제로 적용해보며, 상위 100팀이 오프라인 해커톤에 진출하는 프로그램이다. 이번 첫 챌린지의 목표는 Phase2(챌린지 수료)였다. 결론적으로 목표를 달성했다. 0.17(private) 정도로 수료 기준을 넘겼지만, 사실 기본기 없이 패기만으로 진행했다.


<u>**데이터**</u>를 너무 안일하게 다뤘다. EDA를 통해 데이터의 분포와 성질을 제대로 파악하는 시간이 거의 없었고, 전처리는 NaN이 있는 컬럼 제거와 One-hot Vector Encoding 같은 기본적인 작업만 했다. 데이터 자체의 품질도 좋지 않았다. Major/minor 클래스의 수에 큰 차이가 나는 불균형 데이터셋이었다. 중간에 data leakage 문제도 있어서 데이터가 다시 주어졌을 때도 문제가 있었다. "LG가 데이터를 합쳐서 줬는데 설마 오차가 있을까?"라는 안일한 생각으로 주어진 대로 사용했다. 이 실수는 챌린지 종료 10일 전에 눈사태처럼 돌아왔다. 특정 data row가 어떤 column의 결측치로 인해 다른 column으로 옮겨진 것을 발견했다. 그제서야 다른 컬럼들의 성질에 대해 EDA를 시작했고, 다른 컬럼에서도 문제점이 있었음을 알게 됐다. 아무리 좋은 모델을 만들어도 데이터가 이상하면 의미가 없다는 것을 뼈저리게 느꼈다. 결국 제대로 된 데이터로 처음부터 모델을 다시 만들어야 했다. 다음 챌린지에서는 반드시 데이터 처리를 철저히 한 후 모델링을 시작해야겠다.


<u>**모델링**</u>과 파인튜닝 과정이 생각보다 어려웠다. 사실 이 부분은 "어렵다"고 말하기도 애매하다. 머신러닝 자체와 교차 검증에 대한 이해가 부족한 상태에서 파인튜닝을 무작정 시도해서 그랬던 것 같다. 또한 테이블 형식의 데이터에는 딥러닝 모델 구축이 예상보다 적게 사용된다는 것을 알게 됐다. 아무래도 자연어나 비전 데이터처럼 직접 해석하기 어렵지 않아서 그런 것 같다.


<u>**소통**</u>에도 문제가 있었다. 내가 유독 날카롭게 말했던 것도 있어서 팀원들에게 미안한 마음이 든다. 또한 같은 작업에 대해 용어를 혼용하거나, 나만의 기준으로 나눈 용어를 처음부터 자세히 설명하지 않아 추가 설명을 요청받는 상황이 발생했다. 처음부터 정리하고 더 자세히 설명했다면 좋았을 것 같다. 코드 작성에서도 문제가 있었다. 주석을 너무 간단하게 작성했고, 새로 추가한 코드에는 주석을 아예 달지 않았다. 밤새 새로운 코드를 작성해놓고 설명을 하지 않은 꼴이 됐다.


<u>**기록**</u>의 중요성을 뼈저리게 느꼈다. 사전 학습된 가중치를 저장해봤자 학습 코드가 없으면 재현할 수 없다. 공학/과학도로서 지켜야 할 "재현성"을 그냥 무시해버린 셈이다. 이 실수 역시 제출 15분 전에 눈덩이처럼 커져 돌아왔다. 다음에는 아무리 귀찮아도 config.yaml 같은 설정 파일을 만들어 코드가 제대로 실행되게 해야겠다. 그리고 주피터 노트북은 사용하지 않는 게 좋을 것 같다.


이번 학기에는 Dacon/Kaggle 대회 참가와 관련 강의를 통해 기초를 더 다지고, 겨울방학에 다시 도전해볼 생각이다.

